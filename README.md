# üêæ PetFinderLGBM - Adoption Speed Classifier

**Autor:** Cristian Arenas  
**Lenguajes:** C++ y Python  
**Modelo:** LightGBM (ejecuci√≥n nativa)  
**Base de datos:** SQLite3  
**Sistema:** Windows 64-bit

---

## üìå Descripci√≥n del proyecto

Este proyecto implementa un pipeline completo para el entrenamiento y evaluaci√≥n de un modelo de clasificaci√≥n multiclase que predice la velocidad de adopci√≥n de mascotas (`AdoptionSpeed`). Utiliza LightGBM en su versi√≥n nativa, con un aplicaci√≥n en C++ para control total del proceso y scripts en Python para an√°lisis visual de resultados.
El modelo es entrenado usando validaci√≥n cruzada K-Fold (5 folds) y tambi√©n se entrena un modelo final con todo el dataset. Los resultados se almacenan en SQLite y se visualizan mediante gr√°ficos generados con Python.
Dataset (train.csv) utilizado en el pipeline descargado desde Kaggle: https://www.kaggle.com/competitions/petfinder-adoption-prediction/data.

---

## üß∞ Requisitos

- Windows 10/11 64-bit
- Python 3.x (para visualizaci√≥n)
- Paquetes Python:  
  `pip install matplotlib seaborn pandas`
- LightGBM nativo (`lightgbm.exe`) --- ya se encuentra junto con los archivos del proyecto - web LightGBM: https://lightgbm.readthedocs.io/en/stable/index.html

---

## üöÄ C√≥mo ejecutar

Clonar el proyecto localmente desde tu m√°quina.

Dentro del directorio ra√≠z vas a encontrar todo el c√≥digo fuente por si quieres realizar modificaciones o mejoras que consideres necesarias.
Si lo deseas, puedes abrir el proyecto desde alg√∫n entorno de desarrollo (en mi caso us√© Visual Studio 2022), compilar y ejecutarlo desde ah√≠ mismo.
Si s√≥lo quieres hacer uso del pipeline sin realizar modificaciones, en el directorio ra√≠z del proyecto, encontrar√°s un archivo zip llamado "PetFinderLGBMReady" 
con todo listo para correr. Descomprimirlo.

En la terminal de Windows (cmd o PowerShell):

Desde el directorio ra√≠z del proyecto:

```bash
cd PetFinderLGBMReady
run_pipeline.bat
```

Al correr el archivo run_pipeline.bat, se inicia el pipeline y se ejecuta como ***PRIMER INSTANCIA*** un script Python llamado "optuna_files_creator.py" que se encarga de correr 
la optimizaci√≥n bayesiana de hiperpar√°metros mediante la librer√≠a Optuna. Puedes usar este script para modificarlo y especificar tu propia configuraci√≥n, realizar tu propia 
feature engineering con el dataset, cambiar hiperpar√°metros, semilla a utilizar, etc.

Qu√© hace este script?

 -Carga y transforma los datos.

 -Realiza feature engineering con nuevas variables como CareLevel, ColorCount, HasPhotoVideo, FeeBin, etc.

 -Define un conjunto de variables explicativas (features) y la variable respuesta (AdoptionSpeed).

 -Divide los datos para optimizaci√≥n.

 -Separa los datos en entrenamiento y validaci√≥n (80/20) estratificadamente para mantener la distribuci√≥n de clases.

 -Define un espacio de b√∫squeda de hiperpar√°metros.

 -Usa Optuna para explorar autom√°ticamente combinaciones de hiperpar√°metros de LightGBM como:

	*learning_rate

	*num_leaves

	*min_data_in_leaf

	*feature_fraction

	*bagging_fraction

	*lambda_l1, lambda_l2, etc.

 -Eval√∫a cada combinaci√≥n usando Cross-Validation (CV).

 -Por cada combinaci√≥n de hiperpar√°metros, se entrena un modelo LightGBM en 3 folds.

 -Se utiliza la m√©trica Cohen's Kappa como objetivo de maximizaci√≥n, que mide la concordancia entre predicci√≥n y realidad.

 -Guarda la mejor configuraci√≥n.

 -Imprime los mejores hiperpar√°metros encontrados.

 -Utiliza estos par√°metros para generar los archivos de entrenamiento y predicci√≥n.

 -Genera archivos para utilizar luego en la aplicaci√≥n C++ de entrenamiento y an√°lisis.

 -Crea archivos .txt con los datos de entrenamiento y validaci√≥n por fold.

 -Genera archivos de configuraci√≥n (config_train_fold_*.txt, config_pred_fold_*.txt, etc.).

 -Tambi√©n crea el dataset completo train_all.txt y su archivo de configuraci√≥n config_train_all.txt para utilizar en el entrenamiento final con todos los datos.

Una vez que el script Python termin√≥ de correr, pasamos a la ***SEGUNDA INSTANCIA*** donde se inicia el programa en C++ para el entrenamiento, evaluaci√≥n y an√°lisis 
de los modelos LGBM para predecir la velocidad con la que se adoptan las mascotas en el dataset PetFinder. Se utiliza LGBM nativo para entrenar cada una de las 5 folds y 
el modelo final con todos los datos.

Descripci√≥n general de este programa:

 -Modelado con LightGBM nativo.

 -Almacenamiento y trazabilidad con SQLite3.

 -Visualizaciones con Python.

 -Reportes y m√©tricas avanzadas.

 
 Validaci√≥n Cruzada (K-Fold)

 -Para cada uno de los 5 folds:

  -Entrena un modelo LightGBM usando el archivo config_train_fold_i.txt.

  -Predice sobre el fold de validaci√≥n con config_pred_fold_i.txt.

  -Calcula las m√©tricas:

   -Accuracy.

   -F1 macro.

   -Cohen‚Äôs Kappa.

 -Guarda:

  -Resultados y predicciones en archivos .csv.

  -Matriz de confusi√≥n (como imagen y CSV).

  -M√©tricas en la base de datos resultados.db (tabla resultados).

  -Predicciones en la tabla predicciones.

 -Genera visualizaciones con scripts Python (ejecuta autom√°ticamente los scripts de Python):
  
  -Matr√≠z de confusi√≥n por fold y final.

  -Evoluci√≥n de m√©tricas durante experimentos.
  
  -Importancia de variables.

 -Resumen Promedio:
  
  -Muestra y almacena m√©tricas promedio de todos los folds.
 
Entrenamiento Final sobre todo el Dataset:

 -Entrena utilizando todos los datos con el mejor modelo.
 
 -Realiza predicciones.

 -Calcula m√©tricas finales (Accuracy, F1 y Kappa).

 -Genera y guarda matriz de confusi√≥n.
 
 -Almacena resultados en SQLite como modelo final.

 -Visualiza gr√°ficos para an√°lisis.


***Como resultado se genera un modelo binario para llevar a producci√≥n***

---

## üìä M√©tricas utilizadas

- **Accuracy**
- **F1 Macro**
- **Cohen's Kappa**
- **Matriz de confusi√≥n**
- **Importancia de variables**

---

## üñºÔ∏è Visualizaciones

Se generan autom√°ticamente:

- `metricas_por_fold.png` ‚Üí gr√°fico de barras comparativo
- `evolucion_metricas.png` ‚Üí evoluci√≥n temporal
- `ranking_f1_macro.png` ‚Üí ranking de experimentos
- `conf_matrix_fold_*.png` ‚Üí matrices de confusi√≥n
- `importancia_variables.png` ‚Üí importancia de variables

---

## üß™ Base de datos SQLite

El archivo `resultados.db` guarda:

- M√©tricas por experimento (accuracy, F1, Kappa)
- Hiperpar√°metros utilizados
- Predicciones reales y estimadas

Esto permite trazabilidad, auditor√≠a y rean√°lisis.

---

## ‚úÖ Ventajas de esta implementaci√≥n

- M√°ximo rendimiento gracias al uso de **LightGBM nativo en C++**
- C√≥digo modular y reutilizable
- Visualizaci√≥n clara con Python + Matplotlib
- Resultados persistentes en **SQLite**
- Ideal para **entornos productivos** o **an√°lisis robustos** en competencias

---

## üì¨ Contacto

Para consultas o mejoras:  
**Cristian Arenas** ‚Äì cdarenas78@gmail.com

---

## üìù Licencia

MIT License.